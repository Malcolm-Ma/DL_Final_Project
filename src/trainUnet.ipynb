{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import *\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join('..', 'input', '2015_BOE_Chiu', '2015_BOE_Chiu')\n",
    "subject_path = [os.path.join(input_path, 'Subject_0{}.mat'.format(i)) for i in range(1, 10)] + [os.path.join(input_path, 'Subject_10.mat')]\n",
    "\n",
    "data_indexes = [10, 15, 20, 25, 28, 30, 32, 35, 40, 45, 50]\n",
    "\n",
    "width = 768\n",
    "height = 496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(subject_path[0])\n",
    "img_tensor = mat['images']\n",
    "manual_fluid_tensor_1 = mat['manualFluid1']\n",
    "\n",
    "img_array = np.transpose(img_tensor, (2, 0, 1))\n",
    "manual_fluid_array = np.transpose(manual_fluid_tensor_1, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_array[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(manual_fluid_array[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresh(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "thresh = np.vectorize(thresh, otypes=[np.float])\n",
    "\n",
    "def create_dataset(paths):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for path in paths:\n",
    "        mat = scipy.io.loadmat(path)\n",
    "        img_tensor = mat['images']\n",
    "        fluid_tensor = mat['manualFluid1']\n",
    "        \n",
    "        img_array = np.transpose(img_tensor, (2, 0 ,1)) / 255\n",
    "        fluid_array = np.transpose(fluid_tensor, (2, 0 ,1))\n",
    "        fluid_array = thresh(fluid_array)\n",
    "        \n",
    "        for idx in data_indexes:\n",
    "            x += [np.expand_dims(img_array[idx], 2)]\n",
    "            y += [np.expand_dims(fluid_array[idx], 2)]\n",
    "        \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x_train, y_train = create_dataset(subject_path[:9])\n",
    "x_val, y_val = create_dataset(subject_path[9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (height,width,1)\n",
    "\n",
    "inputs = Input(input_size)\n",
    "conv1 = Conv2D(8, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv1 = Conv2D(8, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(12, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv2 = Conv2D(12, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(16, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv3 = Conv2D(16, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(24, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = Conv2D(24, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "# pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "up6 = Conv2D(24, (2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size=(2,2))(drop5))\n",
    "# up6 = Conv2DTranspose(24, (2, 2), strides=(2, 2), padding='same')(drop5)\n",
    "# up6 = Conv2DTranspose(24, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "merge6 = concatenate([drop4, up6], axis=3)\n",
    "# merge6 = concatenate([conv4, up6])\n",
    "conv6 = Conv2D(24, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(24, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2D(16, (2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size=(2,2))(conv6))\n",
    "merge7 = concatenate([conv3,up7], axis=3)\n",
    "conv7 = Conv2D(16, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(16, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2D(12, (2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size=(2,2))(conv7))\n",
    "merge8 = concatenate([conv2,up8], axis=3)\n",
    "conv8 = Conv2D(12, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(12, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2D(8, (2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size=(2,2))(conv8))\n",
    "merge9 = concatenate([conv1,up9], axis=3)\n",
    "conv9 = Conv2D(8, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(8, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = Conv2D(2, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "model.compile(optimizer=Adam(lr = 1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model1.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size = (height,width,1)\n",
    "\n",
    "# Another model\n",
    "inputs = Input(input_size)\n",
    "conv1 = Conv2D(8, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv1 = Conv2D(8, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(12, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv2 = Conv2D(12, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(16, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv3 = Conv2D(16, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(24, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = Conv2D(24, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "# drop4 = Dropout(0.5)(conv4)\n",
    "# pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(32, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = Conv2D(32, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "# drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "# up6 = Conv2DTranspose(24, (2, 2), strides=(2, 2), padding='same')(drop5)\n",
    "up6 = Conv2DTranspose(24, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "# merge6 = concatenate([drop4, up6])\n",
    "merge6 = concatenate([conv4, up6])\n",
    "conv6 = Conv2D(24, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(24, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "merge7 = concatenate([conv3,up7])\n",
    "conv7 = Conv2D(16, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(16, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2DTranspose(12, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "merge8 = concatenate([conv2,up8])\n",
    "conv8 = Conv2D(12, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(12, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "merge9 = concatenate([conv1,up9])\n",
    "conv9 = Conv2D(8, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(8, (3, 3), activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "model_1 = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=11, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (pred > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 6\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=3, figsize=(15, 10))\n",
    "for i in range(nrows):\n",
    "    axes[i][0].imshow(np.reshape(x_val[2*i], (496, 768)))\n",
    "    axes[i][1].imshow(np.reshape(y_val[2*i], (496, 768)))\n",
    "    axes[i][2].imshow(np.reshape(pred[2*i], (496, 768)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = results.history['accuracy']\n",
    "val_acc = results.history['val_accuracy']\n",
    "loss = results.history['loss']\n",
    "val_loss = results.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "ax.plot(epochs, acc, 'ro', label='Training acc')\n",
    "ax.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "ax.set_title('Accuracy without data augmentation', fontsize=22)\n",
    "ax.set_xlabel(r'Epochs', fontsize=22)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=22)\n",
    "ax.tick_params(labelsize=22)\n",
    "ax.legend(fontsize=24)\n",
    "\n",
    "figL, axL = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "axL.plot(epochs, loss, 'ro', label='Training loss')\n",
    "axL.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "axL.set_title('Loss without data augmentation', fontsize=22)\n",
    "axL.set_xlabel(r'Epochs', fontsize=22)\n",
    "axL.set_ylabel(r'Loss', fontsize=22)\n",
    "axL.tick_params(labelsize=22)\n",
    "axL.legend(fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
